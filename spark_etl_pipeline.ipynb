{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "962eaa99-cdc8-4cbf-9eba-7189ecd28c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### #ETL PIPELINE IN BRONZE, SILVER, AND GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83dc423-b068-4a5c-b63f-bfcdc08b9c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bronze layer exists\nCreating Silver layer...\n✓ Silver layer created with schema overwrite\n✓ Silver layer created: 112650 rows\nCreating Gold layer...\n✓ Gold layer created\n\n=== Pipeline Summary ===\nBronze.customer: 99441 rows\nSilver.sales_cleaned: 112650 rows\nGold.sales_by_category: 74 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, trim, lower, current_timestamp, sum, avg, count\n",
    "\n",
    "# ============================================\n",
    "# BRONZE LAYER - Raw data ingestion\n",
    "# ============================================\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "\n",
    "# Load raw data to bronze (already done)\n",
    "print(\"✓ Bronze layer exists\")\n",
    "\n",
    "# ============================================\n",
    "# SILVER LAYER - Data Cleaning & Validation\n",
    "# ============================================\n",
    "print(\"Creating Silver layer...\")\n",
    "\n",
    "# Read from Bronze\n",
    "customer = spark.table(\"bronze.customer\").drop(\"injection_date\")\n",
    "product = spark.table(\"bronze.product\").drop(\"injection_date\")\n",
    "order = spark.table(\"bronze.order\").drop(\"injection_date\")\n",
    "orders = spark.table(\"bronze.orders\").drop(\"injection_date\")\n",
    "\n",
    "# Join\n",
    "sales_joined = (\n",
    "    order\n",
    "    .join(orders, \"order_id\", \"left\")\n",
    "    .join(customer, \"customer_id\", \"left\")\n",
    "    .join(product, \"product_id\", \"left\")\n",
    ")\n",
    "\n",
    "# Clean in Silver\n",
    "sales_clean = (sales_joined\n",
    "    .withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
    "    .withColumn(\"freight_value\", col(\"freight_value\").cast(\"double\"))\n",
    "    .dropDuplicates()\n",
    "    .dropna(subset=[\"order_id\", \"customer_id\"])\n",
    "    .filter((col(\"price\").isNull()) | (col(\"price\") >= 0))\n",
    "    .withColumn(\"order_status\", trim(lower(col(\"order_status\"))))\n",
    "    .withColumn(\"processed_date\", current_timestamp())\n",
    ")\n",
    "\n",
    "# Save Silver\n",
    "# Add the overwriteSchema option\n",
    "sales_clean.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"silver.sales_cleaned\")\n",
    "\n",
    "print(\"✓ Silver layer created with schema overwrite\")\n",
    "print(f\"✓ Silver layer created: {sales_clean.count()} rows\")\n",
    "\n",
    "# ============================================\n",
    "# GOLD LAYER - Business Aggregations\n",
    "# ============================================\n",
    "print(\"Creating Gold layer...\")\n",
    "\n",
    "silver_df = spark.table(\"silver.sales_cleaned\")\n",
    "\n",
    "# Business metric 1: Sales by category\n",
    "(silver_df.groupBy(\"product_category_name\")\n",
    "    .agg(\n",
    "        count(\"order_id\").alias(\"total_orders\"),\n",
    "        sum(\"price\").alias(\"total_revenue\"),\n",
    "        avg(\"price\").alias(\"avg_order_value\")\n",
    "    )\n",
    "    .write.format(\"delta\").mode(\"overwrite\")\n",
    "    .saveAsTable(\"gold.sales_by_category\"))\n",
    "\n",
    "# Business metric 2: Customer lifetime value\n",
    "(silver_df.groupBy(\"customer_id\", \"customer_unique_id\", \"customer_state\")\n",
    "    .agg(\n",
    "        count(\"order_id\").alias(\"total_orders\"),\n",
    "        sum(\"price\").alias(\"lifetime_value\")\n",
    "    )\n",
    "    .write.format(\"delta\").mode(\"overwrite\")\n",
    "    .saveAsTable(\"gold.customer_lifetime_value\"))\n",
    "\n",
    "print(\"✓ Gold layer created\")\n",
    "\n",
    "# Verify the pipeline\n",
    "print(\"\\n=== Pipeline Summary ===\")\n",
    "print(f\"Bronze.customer: {spark.table('bronze.customer').count()} rows\")\n",
    "print(f\"Silver.sales_cleaned: {spark.table('silver.sales_cleaned').count()} rows\")\n",
    "print(f\"Gold.sales_by_category: {spark.table('gold.sales_by_category').count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8119ee4a-4335-4fb0-be3f-4f6684d8cf2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gold.monthly_sales...\n✓ gold.monthly_sales: 24 months\n\nCreating gold.top_customers...\n✓ gold.top_customers: 1000 customers\n\n✅ Additional Gold tables created!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum, avg, countDistinct, month, year\n",
    "\n",
    "silver_df = spark.table(\"silver.sales_cleaned\")\n",
    "\n",
    "# Gold: Monthly sales trend\n",
    "print(\"Creating gold.monthly_sales...\")\n",
    "monthly_sales = silver_df.groupBy(\n",
    "    year(\"order_purchase_timestamp\").alias(\"year\"),\n",
    "    month(\"order_purchase_timestamp\").alias(\"month\")\n",
    ").agg(\n",
    "    count(\"order_id\").alias(\"total_orders\"),\n",
    "    sum(\"price\").alias(\"total_revenue\"),\n",
    "    avg(\"price\").alias(\"avg_order_value\"),\n",
    "    countDistinct(\"customer_id\").alias(\"unique_customers\")\n",
    ").orderBy(\"year\", \"month\")\n",
    "\n",
    "monthly_sales.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.monthly_sales\")\n",
    "print(f\"✓ gold.monthly_sales: {monthly_sales.count()} months\")\n",
    "\n",
    "# Gold: Top customers\n",
    "print(\"\\nCreating gold.top_customers...\")\n",
    "top_customers = silver_df.groupBy(\"customer_id\", \"customer_unique_id\", \"customer_state\").agg(\n",
    "    count(\"order_id\").alias(\"total_orders\"),\n",
    "    sum(\"price\").alias(\"total_spent\"),\n",
    "    avg(\"price\").alias(\"avg_order_value\")\n",
    ").orderBy(col(\"total_spent\").desc()).limit(1000)\n",
    "\n",
    "top_customers.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.top_customers\")\n",
    "print(f\"✓ gold.top_customers: {top_customers.count()} customers\")\n",
    "\n",
    "print(\"\\n✅ Additional Gold tables created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4de7a9-fd69-4e05-b37b-b946cd10d8a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n============================================================\nFINAL PIPELINE STATUS\n============================================================\n\n\uD83D\uDCE6 BRONZE (Raw):\n  bronze.customer: 99,441 rows\n  bronze.product: 32,951 rows\n  bronze.order: 112,650 rows\n  bronze.orders: 99,441 rows\n\n\uD83D\uDD27 SILVER (Cleaned):\n  silver.sales_cleaned: 112,650 rows\n\n⭐ GOLD (Business Metrics):\n  gold.sales_by_category: 74 categories\n  gold.customer_metrics: 98,666 customers\n\n✅ Medallion Architecture Complete!\n============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL PIPELINE STATUS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\uD83D\uDCE6 BRONZE (Raw):\")\n",
    "print(f\"  bronze.customer: {spark.table('bronze.customer').count():,} rows\")\n",
    "print(f\"  bronze.product: {spark.table('bronze.product').count():,} rows\")\n",
    "print(f\"  bronze.order: {spark.table('bronze.order').count():,} rows\")\n",
    "print(f\"  bronze.orders: {spark.table('bronze.orders').count():,} rows\")\n",
    "\n",
    "print(\"\\n\uD83D\uDD27 SILVER (Cleaned):\")\n",
    "print(f\"  silver.sales_cleaned: {spark.table('silver.sales_cleaned').count():,} rows\")\n",
    "\n",
    "print(\"\\n⭐ GOLD (Business Metrics):\")\n",
    "print(f\"  gold.sales_by_category: {spark.table('gold.sales_by_category').count():,} categories\")\n",
    "print(f\"  gold.customer_metrics: {spark.table('gold.customer_metrics').count():,} customers\")\n",
    "print(\"\\n✅ Medallion Architecture Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spark_etl_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}